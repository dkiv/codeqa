# .env.example
# Example environment variables for API keys and secrets.
# Copy to .env and fill in with your own values.

# --- Required ---
# OpenAI API key for chat model calls (only needed if you enable the LLM in rag_chain.py)
OPENAI_API_KEY=your_openai_api_key_here

# Path where the Chroma index is persisted (ingest.py writes here; rag_chain.py reads from here)
INDEX_PATH=./data/index

# --- Models ---
# Embedding model used by ingest.py and rag_chain.py (must match your built index)
EMBEDDING_MODEL=BAAI/bge-small-en

# Chat model name (used if you enable the LLM call in rag_chain.py)
CHAT_MODEL=gpt-4o-mini

# Default temperature for chat model
CHAT_TEMPERATURE=0.0

# --- Retrieval ---
# Top-k neighbors to fetch from the vector store
RETRIEVAL_K=8
# Max number of chunks from retriever to include in the prompt
MAX_CONTEXT_CHUNKS=6
# Max characters per chunk when formatting context
MAX_CHUNK_CHARS=1200

# --- Server (only if you later add an API) ---
# Port for a FastAPI/uvicorn app (unused for now)
APP_PORT=8000